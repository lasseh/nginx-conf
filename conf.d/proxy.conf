# =============================================================================
# NGINX PROXY CONFIGURATION
# =============================================================================
# Optimized settings for reverse proxy scenarios including load balancing,
# microservices, and backend application servers

# =============================================================================
# HTTP PROTOCOL OPTIMIZATION
# =============================================================================

# Use HTTP/1.1 for upstream connections to enable connection reuse
# Why: HTTP/1.1 supports keep-alive connections, reducing connection overhead
# Impact: Improves performance by reusing TCP connections to backend servers
# Essential for: Modern web applications and API backends
proxy_http_version                 1.1;

# =============================================================================
# SSL/TLS BACKEND COMMUNICATION
# =============================================================================

# Enable SNI (Server Name Indication) when connecting to HTTPS backends
# Why: Required for backends using SSL with multiple domains on same IP
# Impact: Ensures proper SSL certificate selection on multi-domain backends
# Critical for: Modern SSL/TLS setups and CDN backends
proxy_ssl_server_name              on;

# =============================================================================
# PROXY HEADERS - CLIENT INFORMATION PRESERVATION
# =============================================================================
# Forward essential client information to backend servers for proper handling

# Preserve the original Host header from client request
# Why: Backend applications need to know the original domain requested
# Impact: Enables proper virtual host handling and URL generation
proxy_set_header Host              $host;

# Close connections by default (WebSocket support requires separate config)
# Why: Standard HTTP connections should be properly closed after response
# Impact: Prevents connection leaks and ensures proper resource cleanup
proxy_set_header Connection        "close";

# Send the real client IP address to backend
# Why: Backend logs and security systems need actual client IPs
# Impact: Enables proper rate limiting, geolocation, and security analysis
proxy_set_header X-Real-IP         $remote_addr;

# RFC 7239 compliant forwarded header with full proxy chain info
# Why: Modern standard for proxy information, includes protocol and host
# Impact: Provides comprehensive proxy chain information for compliance
proxy_set_header Forwarded         $proxy_add_forwarded;

# Traditional forwarded-for header with proxy chain
# Why: Legacy compatibility for applications expecting this header
# Impact: Maintains compatibility with older applications and frameworks
proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;

# Forward the original protocol (http/https) to backend
# Why: Backend needs to know if original request was secure
# Impact: Enables proper redirect handling and security policy enforcement
proxy_set_header X-Forwarded-Proto $scheme;

# Forward the original host header to backend
# Why: Backend applications may need original hostname for URL generation
# Impact: Ensures proper absolute URL generation in backend responses
proxy_set_header X-Forwarded-Host  $host;

# Forward the original port number to backend
# Why: Backend may need port information for proper URL construction
# Impact: Enables correct port handling in redirects and absolute URLs
proxy_set_header X-Forwarded-Port  $server_port;

# Forward unique request identifier for tracing and debugging
# Why: Enables request correlation across microservices and logs
# Impact: Improves debugging, monitoring, and distributed tracing capabilities
proxy_set_header X-Request-ID      $request_id;

# =============================================================================
# PROXY TIMEOUT CONFIGURATION
# =============================================================================
# Balanced timeouts to handle various backend response patterns

# Maximum time to establish connection with backend server
# Why: 60s matches nginx defaults and handles slow backend startup gracefully
# Impact: Balances reliability with responsiveness for backend connections
# Note: Cannot exceed 75s due to system limitations
proxy_connect_timeout              60s;

# Maximum time to send request to backend server
# Why: 60s accommodates large request bodies and slow backend processing
# Impact: Prevents timeouts on file uploads and complex API requests
proxy_send_timeout                 60s;

# Maximum time to receive response from backend server
# Why: 60s handles most backend processing while preventing resource exhaustion
# Impact: Balances user experience with server resource protection
proxy_read_timeout                 60s;

# =============================================================================
# PROXY BUFFERING OPTIMIZATION
# =============================================================================
# Optimize memory usage and response handling for better performance

# Enable response buffering to improve client connection handling
# Why: Allows nginx to buffer slow backend responses and serve clients faster
# Impact: Reduces backend connection time and improves client experience
proxy_buffering                    on;

# Buffer size for reading response headers from backend
# Why: 8k handles larger headers and modern applications efficiently
# Impact: Accommodates complex headers without performance degradation
# Default: Matches current nginx defaults (4k or 8k depending on platform)
proxy_buffer_size                  8k;

# Number and size of buffers for reading backend response body
# Why: 8 buffers of 8k (64k total) improves performance for modern applications
# Impact: Better handles larger responses and reduces buffer overflow to disk
# Optimization: Balances memory usage with throughput for typical workloads
proxy_buffers                      8 8k;

# Maximum size of buffers that can be busy sending to client
# Why: 16k (2 buffers) enables better concurrent read/write operations
# Impact: Improves throughput by allowing more data to be processed simultaneously
# Performance: Reduces context switching between read and write operations
proxy_busy_buffers_size            16k;

# =============================================================================
# MODERN PROXY OPTIMIZATIONS
# =============================================================================
# Additional settings for improved performance and reliability

# Enable TCP keepalive for backend connections
# Why: Reduces connection overhead and improves backend connection reuse
# Impact: Better performance for high-traffic scenarios and connection pooling
# Modern: Recommended for production environments with persistent backends
proxy_socket_keepalive             on;

# Ignore client disconnections during backend processing
# Why: Prevents backend request cancellation when clients disconnect early
# Impact: Reduces backend load and prevents incomplete processing
# Use case: Important for APIs that perform critical operations
proxy_ignore_client_abort          off;

# Maximum size of temporary files for large responses
# Why: 1GB limit prevents disk exhaustion while allowing large file proxying
# Impact: Balances functionality with disk space protection
# Default: Matches nginx default of 1024m
proxy_max_temp_file_size           1024m;
