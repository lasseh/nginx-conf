# =============================================================================
# SERVER-SENT EVENTS (SSE) EXAMPLE CONFIGURATION
# =============================================================================
# Reference configuration for SSE proxying in nginx
# Copy relevant sections to your site configuration as needed
#
# SSE provides unidirectional real-time communication from server to client
# Uses standard HTTP/HTTPS with Content-Type: text/event-stream

# =============================================================================
# SSE VS WEBSOCKET
# =============================================================================
# SSE: Server → Client only, automatic reconnection, simpler
# WebSocket: Bidirectional, manual reconnection, more complex

# =============================================================================
# BASIC SSE LOCATION BLOCK
# =============================================================================
# Only 4 directives beyond standard proxy setup are needed for SSE:
#   1. proxy_buffering off    — prevents nginx from holding events in buffers
#   2. proxy_read_timeout     — keeps idle connections alive (backend should send heartbeats)
#   3. proxy_http_version 1.1 — required for chunked transfer encoding
#   4. proxy_set_header Connection "" — enables keepalive to upstream

location /events {
    proxy_pass http://sse_backend;

    # Standard proxy headers
    include snippets/proxy-headers.conf;

    # Disable proxy buffering — required for real-time SSE streaming
    # Without this, nginx holds events until the buffer fills
    proxy_buffering                    off;

    # Long timeout for idle SSE connections
    # Backend should send periodic heartbeat comments to prevent timeout
    proxy_read_timeout                 24h;

    # HTTP/1.1 with keepalive for chunked transfer encoding
    proxy_http_version                 1.1;
    proxy_set_header Connection        "";

    # Optional: Add CORS headers for cross-origin SSE
    # add_header Access-Control-Allow-Origin *;
    # add_header Access-Control-Allow-Methods "GET, OPTIONS";
    # add_header Access-Control-Allow-Headers "Cache-Control, Authorization";
}

# =============================================================================
# SSE WITH AUTHENTICATION AND RATE LIMITING
# =============================================================================

location /secure-events {
    # Rate limiting for SSE connections
    limit_req zone=api burst=5 nodelay;

    proxy_pass http://sse_backend;

    # Standard proxy headers
    include snippets/proxy-headers.conf;

    # SSE-specific settings
    proxy_buffering                    off;
    proxy_read_timeout                 24h;
    proxy_http_version                 1.1;
    proxy_set_header Connection        "";
}

# =============================================================================
# SSE ON A SPECIFIC API PATH
# =============================================================================
# When only certain paths under an API are SSE streams, use a regex or
# suffix match to apply SSE settings only to those endpoints.
# Non-stream requests under /api/ keep normal proxy behavior.
#
# Example: /api/devices/{hostname}/interfaces/stream

# Option 1: Match a specific suffix (simplest, recommended)
# Any path ending in /stream gets SSE treatment
location ~ /stream$ {
    proxy_pass              http://sse_backend;
    include                 snippets/proxy-headers.conf;

    proxy_buffering         off;
    proxy_read_timeout      24h;
    proxy_http_version      1.1;
    proxy_set_header Connection "";
}

# Option 2: Match a specific path pattern with regex
# Only matches /api/devices/*/interfaces/stream
location ~ ^/api/devices/[^/]+/interfaces/stream$ {
    proxy_pass              http://sse_backend;
    include                 snippets/proxy-headers.conf;

    proxy_buffering         off;
    proxy_read_timeout      24h;
    proxy_http_version      1.1;
    proxy_set_header Connection "";
}

# Option 3: Nested location inside an existing /api/ block
# Useful when /api/ already has proxy_pass and you just need to
# override buffering and timeouts for stream endpoints
#
# location /api/ {
#     proxy_pass              http://api_backend;
#     include                 snippets/proxy-headers.conf;
#
#     # SSE override for stream endpoints
#     location ~ /stream$ {
#         proxy_pass              http://api_backend;
#         include                 snippets/proxy-headers.conf;
#
#         proxy_buffering         off;
#         proxy_read_timeout      24h;
#         proxy_http_version      1.1;
#         proxy_set_header Connection "";
#     }
# }

# =============================================================================
# SSE BACKEND DEFINITION
# =============================================================================

upstream sse_backend {
    # Use least_conn for better load distribution with long-lived connections
    least_conn;

    # SSE backend servers
    server backend1.example.com:8080;
    server backend2.example.com:8080;

    # Keep connections alive for efficiency
    keepalive 32;
    keepalive_requests 1000;
    keepalive_timeout 60s;
}

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================
# 1. Copy the location block you need to your site configuration
# 2. Copy the upstream block and customize your backend servers
# 3. For simple SSE: use the basic location block
# 4. For authenticated SSE: use the secure location block
# 5. Test with: curl -N -H "Accept: text/event-stream" http://your-domain/events
#
# BACKEND REQUIREMENTS:
# - Send Content-Type: text/event-stream
# - Use proper SSE format: "data: message\n\n"
# - Handle client disconnections gracefully
# - Implement heartbeat/keep-alive comments (e.g., ": ping\n\n" every 30s)
#   to prevent proxy_read_timeout from closing idle connections
#
# WHAT'S NOT NEEDED:
# - proxy_set_header Accept — client already sends this, nginx forwards it
# - proxy_set_header Cache-Control — don't overwrite client request headers
# - proxy_set_header X-Accel-Buffering — this is a response header the backend
#   sends to nginx; setting it as a request header does nothing
# - proxy_cache off — proxy_buffering off already prevents caching
# - proxy_send_timeout 24h — SSE is server→client; client sends nothing after
#   the initial request, so the default send timeout is fine
